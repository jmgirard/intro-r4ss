---
format: 
  revealjs:
    css: ../../styles.css
    slide-number: true
    show-slide-number: all
    progress: true
    history: true
    hash-type: number
    theme: default
    code-block-background: true
    highlight-style: github
    code-link: false
    code-copy: true
    controls: true
    pagetitle: "Intro R4SS Day 2B"
    author-meta: "Jeffrey Girard"
    date-meta: "2023-06-02"
---

::: {.my-title}
# [Introduction to R]{.blue2} <br />for Social Scientists

::: {.my-grey}
[Workshop Day 2B | 2023-06-02]{}<br />
[Jeffrey M. Girard | Pitt Methods]{}
:::

![](../../img/proud_coder_2780E3.svg){.absolute bottom=0 right=0 width=400}
:::

## Basic Regression {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   [Basic regression]{.b .blue} predicts one variable $y$ from another variable $x$ using a straight line

::: {.fragment .mt1}
-   This line is defined by two parameters
    -   The [intercept]{.b .green} is the value of $y$ when $x=0$
    -   The [slope]{.b .green} is the change in $y$ expected for a change of 1 in $x$ (from $x=0$ to $x=1$)
:::

::: {.fragment .mt1}
-   We will use `lm()` to fit regression models
    -   This will solve using ordinary least squares
    -   We need to give it the [data]{.b .green} and a [formula]{.b .green}
:::
:::

::: {.column .tc .pv5 width="40%"}
{{< li ogfgksuz trigger=loop delay=3000 colors=secondary:#2a76dd class=rc >}}
:::
:::


## Basic Regression Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# SETUP: Load the used packages (if needed) and read in the example dataset

library(tidyverse)
library(easystats)

yearspubs <- read_csv("yearspubs.csv")
yearspubs

# ==============================================================================

# LESSON: Regression is a special case of the linear model, so we use lm()

fit <- lm(
  formula = salary ~ years_since_phd,
  data = yearspubs
)

# ==============================================================================

# TIP: Get a parameter summary using model_parameters()

fit

model_parameters(fit)

# ==============================================================================

# TIP: Get effect sizes (standardized results) using standardize = "refit"

model_parameters(fit, standardize = "refit")

# ==============================================================================

# TIP: Get a performance summary using model_performance()

model_performance(fit)

# ==============================================================================

# TIP: Visualize the model expectations using estimate_relation()

plot(estimate_relation(fit))

# ==============================================================================

# LESSON: To center the predictor, use center()

yearspubs$years_since_phd = center(yearspubs$years_since_phd)
  
fit_c <- lm(
  formula = salary ~ years_since_phd,
  data = yearspubs
)

model_parameters(fit_c)

plot(estimate_relation(fit))
plot(estimate_relation(fit_c))

# ==============================================================================

# NOTE: Centering will only change the intercept in basic regression

compare_parameters(fit, fit_c)

compare_performance(fit, fit_c)
```


## Multiple Regression {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   We can also include [multiple predictors]{.b .blue} to assess the [partial effect]{.b .green} of each predictor
    -   This allows us to account for the variance shared by the predictors and the outcome

::: {.fragment .mt1}
-   This changes the slopes' interpretations
    -   The slope of $x_1$ is no longer just the change in $y$ expected for a change of 1 in $x_1$
    -   It is now the change in $y$ expected for a change of 1 in $x_1$ **when controlling for $x_2$**
    -   The slope of $x_2$ similarly controls for $x_1$
:::
:::

::: {.column .tc .pv5 width="40%"}
{{< li jmkpuued trigger=loop delay=3000 colors=secondary:#2a76dd class=rc >}}
:::
:::


## Multiple Regression {.smaller}

::: {.columns .pv4}
::: {.column width="45%"}
- In the model $y \sim x_1$
    -   The $x_1$ slope captures [b]{.b .green} + [c]{.b .green}

::: {.fragment .mt1}
- In the model $y \sim x_2$
    -   The $x_2$ slope captures [c]{.b .green} + [f]{.b .green}
:::

::: {.fragment .mt1}
- In the model $y \sim x_1 + x_2$
    -   The $x_1$ slope captures [b]{.b .green} only
    -   The $x_2$ slope captures [f]{.b .green} only
    -   So the overlap of [c]{.b .green} is removed
:::

:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
![](../../img/venn.png)
:::
:::


## Multiple Regression Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# SETUP: Load the used packages (if needed) and read in the example dataset

library(tidyverse)
library(easystats)

yearspubs

# ==============================================================================

# LESSON: To add more predictors to the formula, just separate them by +

fit_yn <- lm(
  formula = salary ~ years_since_phd + n_pubs,
  data = yearspubs
)

model_parameters(fit_yn)

model_parameters(fit_yn, standardize = "refit")

model_performance(fit_yn)

# ==============================================================================

# USECASE: We can compare our models in terms of parameters and performance

fit_y <- lm(salary ~ years_since_phd, data = yearspubs)
fit_n <- lm(salary ~ n_pubs, data = yearspubs)

compare_parameters(fit_yn, fit_y, fit_n)

compare_performance(fit_yn, fit_y, fit_n)
```


## Categorical Predictors {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   To include categorical predictors in regression models, we can use [dummy coding]{.b .blue}
    -   This creates binary predictor variables

::: {.fragment .mt1}
-   One [reference group]{.b .green} does not get a slope
    -   Instead, it controls the model intercept
    -   All other groups' slopes are just deviations from the intercept
:::

::: {.fragment .mt1}
-   There is no need to create dummy codes in R
    -   Just include a [factor]{.b .green} as a predictor variable
    -   The **first level** will be the reference group
:::
:::

::: {.column .tc .pv5 width="40%"}
{{< li cdbgwqyw trigger=loop delay=3000 colors=secondary:#2a76dd class=rc >}}
:::
:::


## Categorical Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# SETUP: Load the used packages (if needed) and read in the example dataset

library(tidyverse)
library(easystats)
library(palmerpenguins)

# ==============================================================================

# USECASE: Compare three groups with regression (instead of oneway anova)

penguins

levels(penguins$species)

fit <- lm(body_mass_g ~ species, data = penguins)

model_parameters(fit) # estimate intercept and slopes

estimate_means(fit, at = "species") # estimate means

model_parameters(fit, standardize = "refit") # estimate standardized effects

model_performance(fit) # estimate model performance

plot(estimate_relation(fit)) # plot model predictions

anova <- aov(fit) # refit as ANOVA
model_parameters(anova) # recreate F-test

# ==============================================================================

# USECASE: Compare the three groups from regression

estimate_contrasts(fit, contrast = "species")

# ==============================================================================

# USECASE: Including multiple categorical predictors

fit2 <- lm(body_mass_g ~ species + sex, data = penguins)

model_parameters(fit2)

estimate_contrasts(fit2, contrast = "species")
estimate_contrasts(fit2, contrast = "sex")

plot(estimate_relation(fit2))

# ==============================================================================

# USECASE: Regression can even mix categorical and continuous predictors!

fit3 <- lm(body_mass_g ~ flipper_length_mm + species, data = penguins)

model_parameters(fit3)

model_parameters(fit3, standardize = "refit") 

model_performance(fit3)

plot(estimate_relation(fit3))
```


## Interaction Effects {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   We may want to know if the effect of one predictor [depends on]{.b .green} the value on another predictor
    -   Does the effect of hours of **exercise** on weight loss *depend on* biological **sex**?
    -   Does the effect of hours of **exercise** on weight loss *depend on* the **effort** put in?

::: {.fragment .mt1}
-   To answer these, we can test [interaction effects]{.b .blue}
    -   Interaction effects are just slopes for the [product]{.b .green} of two or more predictors
    -   We can include continuous and categorical predictors in interaction effects
:::
:::

::: {.column .tc .pv5 width="40%"}
{{< li nmlpnruz trigger=loop delay=3000 colors=secondary:#2a76dd class=rc >}}
:::
:::


## Interactions Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# SETUP: Load the used packages (if needed) and read in the example dataset

library(tidyverse)
library(easystats)

exercise <- read_csv("exercise.csv")
exercise

# ==============================================================================

# LESSON: Fit a model with no interaction effect for comparison

fit1 <- lm(loss ~ hours + sex, data = exercise)

model_parameters(fit1)

plot(estimate_relation(fit1))

# ==============================================================================

# LESSON: Does the effect of hours depend on sex (and vice versa)?

fit2 <- lm(loss ~ hours * sex, data = exercise)

model_parameters(fit2)

plot(estimate_relation(fit2))

# ==============================================================================

# LESSON: Fit a model with no interaction effect for comparison

fit3 <- lm(loss ~ hours + effort, data = exercise)

model_parameters(fit3)

plot(estimate_relation(fit3))

# NOTE: A model with no interaction will have parallel lines

# ==============================================================================

# LESSON: Does the effect of hours depend on effort (and vice versa)?

fit4 <- lm(loss ~ hours * effort, data = exercise)

model_parameters(fit4)

plot(estimate_relation(fit4))

slopes <- estimate_slopes(fit4, trend = "hours", at = "effort")
slopes
plot(slopes)

# TIP: Increase length to estimate more slopes and fill in gaps in the plot

slopes <- estimate_slopes(fit4, trend = "hours", at = "effort", length = 300)
plot(slopes)

# TIP: Swap trend and at to see the reverse

slopes <- estimate_slopes(fit4, trend = "effort", at = "hours", length = 300)
plot(slopes)

# ==============================================================================

# LESSON: Be cautious about higher-level interactions

fit5 <- lm(loss ~ hours * effort * sex, data = exercise)

model_parameters(fit5)

plot(estimate_relation(fit5))
```


## A Formula Resource {.smaller}

::: {.pv4}

<table width="100%">
<tr>
  <th>Formula</th>
  <th colspan=7>Slopes Estimated</th>
</tr>
<tr>
  <td width="30%">`y ~ x`</td>
  <td width="10%">$x$</td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
</tr>
<tr>
  <td>`y ~ x + w`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td></td>
  <td>$xw$</td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x + w + z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w + z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * (w + z)`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td>$xz$</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w * z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td>$xz$</td>
  <td>$wz$</td>
  <td>$xwz$</td>
</tr>
</table>

::: {.pv4}
Note that predictors can be continuous (i.e., numbers) or categorical (i.e., factors), but if a categorical predictor has more than two levels, you will end up with additional slopes.
:::
:::


## Regression Diagnostics {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   LM makes some [assumptions]{.b .green} about the data
    -   If violated, this can lead to...
    -   Biased [coefficient]{.b} estimates
    -   Biased [standard error]{.b} estimates

::: {.fragment .mt1}
-   [Regression Diagnostics]{.b .blue} check for...
    -   Violated assumptions
    -   Outlier observations
    -   Multicollinearity
    -   Prediction quality
:::

:::

::: {.column .tc .pv5 width="40%"}
{{< li oamdefle trigger=loop delay=3000 colors=primary:#2a76dd class=rc >}}
:::
:::


## Diagnostics Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

yearspubs

fit <- lm(salary ~ years_since_phd + n_pubs, data = yearspubs)

# ==============================================================================

# USECASE: Check model diagnostics

check_model(fit)

# TIP: Since this is a big figure, it may be helpful to click the "Zoom" button

# ==============================================================================

# EXPERIMENTAL: Still being developed, but very cool

# install.packages(c("DT", "flexdashboard"))
model_dashboard(fit)
```

## Addressing Violations

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# ==============================================================================

# LESSON: Bootstrapping to address non-normal residuals

fit <- lm(n_pubs ~ years_since_phd, data = yearspubs)

model_parameters(fit)

plot(check_normality(fit))

# install.packages("qqplotr")
plot(check_normality(fit), type = "qq")

model_parameters(fit, bootstrap = TRUE)

# ==============================================================================

# LESSON: Robust standard errors for heteroskedasticity

# Simulate some data is has increasing error variance

set.seed(2023)
simdata <- tibble(
  income = runif(n = 60, min = 0, max = 100),
  rent = abs(5 + (3 * income + rnorm(n = 60, mean = 0, sd = income)) / 5)
)

qplot(x = income, y = rent, data = simdata, geom = "point")

# Fit linear model

fit2 <- lm(rent ~ 1 + income, data = simdata)

# Estimate normal SEs (assuming constant error variance)

model_parameters(fit2)

plot(check_heteroskedasticity(fit2))

# Estimate heteroskedasticity-robust SEs

# install.packages("sandwich")
model_parameters(fit2, vcov = "HC3")

# ==============================================================================

# LESSON: Polynomial regression for non-linear functional form

# Simulate some data that is quadratic (not linear)

set.seed(2023)
simdata <- tibble(
  cost = runif(n = 50, min = 100, max = 120),
  x = cost - 112,
  satisfaction = 10 + 2 * x - 1 * x^2 + rnorm(n = 50, m = 0, sd = 15)
)

# Fit a linear model anyway

fit3a <- lm(satisfaction ~ cost, data = simdata)

model_parameters(fit3a)

check_model(fit3a)

plot(estimate_relation(fit3a))

# Now fit a polynomial model

fit3b <- lm(satisfaction ~ poly(cost, degree = 2), data = simdata)

model_parameters(fit3b)

check_model(fit3b)

er <- estimate_relation(fit3b, length = 300)
plot(er)

# Find where the inflection point is (in terms of the x-variable)

describe_nonlinear(er, x = "cost")
```

## Simple Power Analysis {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   [Power]{.b .green} is the probability of [correctly rejecting]{.b .blue} the null hypothesis (given that that null is wrong)
    -   Power is related to the effect size, $n$, and $\alpha$
    -   If we know three, we can estimate the fourth
    -   *What sample size is needed for 80% power to detect an effect of the expected size or larger?*

::: {.fragment .mt1}
-   What [effect sizes]{.b .green} should we expect?
    -   Ideally base the size on previous studies...
    -   Cohen's $d$ for $t$-tests (e.g., 0.20, 0.50, 0.80)
    -   Cohen's $f$ for ANOVAs (e.g., 0.10, 0.25, 0.40)
    -   Cohen's $f^2$ for regression (e.g., 0.02, 0.15, 0.35)
:::

:::

::: {.column .tc .pv5 width="40%"}
{{< li htqwuudr trigger=loop delay=3000 colors=secondary:#2a76dd class=rc >}}
:::
:::

## Power Analysis Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# install.packages("WebPower")
library(WebPower)

# ==============================================================================

# t-tests

## We want 80% power to detect a difference of d = 0.5 between 2 ind. groups

wp.t(
  power = 0.80,
  alpha = 0.05,
  type = "two.sample",
  d = 0.5 # effect size
)

## We want 80% power to detect a difference of d = 0.5 between 2 dep. groups

wp.t(
  power = 0.80,
  alpha = 0.05,
  type = "paired",
  d = 0.5 # effect size
)

# ==============================================================================

# ANOVAs

## We want 80% power to detect a difference of f = 0.25 between 4 ind. groups

wp.anova(
  power = 0.80,
  alpha = 0.05,
  type = "overall",
  k = 4, # number of groups to compare
  f = 0.25 # effect size
)

# ==============================================================================

# Regression: Omnibus (overall F-test)

## We want 80% power to explain 10% of the variance in y with 5 predictors

r2_full <- 0.10
r2_reduced <- 0
f2 <- (r2_full - r2_reduced) / (1 - r2_full)
f2

wp.regression(
  power = 0.80,
  alpha = 0.05,
  p1 = 5, # number of predictors in full model
  p2 = 0, # number of predictors in reduced model
  f2 = f2 # effect size
)

# ==============================================================================

# Regression: Targeted (slope's t-test)

## Imagine we can explain 10% of the variance in y using x1 and x2
## We want 80% power to detect an effect of x3 that explains an additional 5%

r2_full <- 0.15
r2_reduced <- 0.10
f2 <- (r2_full - r2_reduced) / (1 - r2_full)
f2

wp.regression(
  power = 0.80,
  alpha = 0.05,
  p1 = 3, # number of predictors in full model
  p2 = 2, # number of predictors in reduced model
  f2 = f2 # effect size
)
```

